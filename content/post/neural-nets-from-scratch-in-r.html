---
title: "Neural Nets: From Linear Regression to Deep Nets"
author: "Christoph"
date: 2018-10-07T14:41:14-05:00
categories: ["R"]
tags: ["R", "neural networks"]
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/viz/viz.js"></script>
<link href="/rmarkdown-libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
<script src="/rmarkdown-libs/grViz-binding/grViz.js"></script>


<p>Neural networks, especially deep neural networks, have received a lot of attention over the last couple of years. They perform remarkably well on image and speech recognition and form the backbone of the technology used for self-driving cars.</p>
<p>What many people find hard to believe is that the mathematics of neural networks have been around for quite some time already. For example, Kurt Hornik proofed the <em>universal approximation theorem</em> of neural networks in 1991 (see <a href="https://www.sciencedirect.com/science/article/pii/089360809190009T">Approximation capabilities of multilayer feedforward networks</a>). The theorem states that neural networks can under mild assumptions approximate arbitrary functions. As we will see, training a neural network is equivalent to solving a very complex multi-dimensional optimization problem. The backpropagation algorithm used to train many neural networks has been around since about the 1960s, but only the vast increase in compute power from cpus and gpus over the last years made training more complex neural networks computationally feasible.</p>
<p>The mathematical reasons for why neural networks perform so well in practice for many tasks such as image classification are still poorly understood though. A very interesting article by Quanta Magazine <a href="https://www.quantamagazine.org/machine-learning-confronts-the-elephant-in-the-room-20180920/">‘Machine Learning Confronts the Elephant in the Room’</a> highlights a very fundamental issue with neural nets: they can easily be confused in potentially serious ways. Researchers found that a neural network that was able to classify objects in a room correctly with high confidence was derailed when they added an elephant to the picture. The network misidentified a chair as a couch and failed to spot objects it found earlier. While such hicups might seem funny at first glance, imagine a self-driving car suddenly ignoring a child, because it saw a person in an elefant costume before.</p>
<p>I strongly believe that getting an understanding of how neural nets work is essential to get a feeling for when they might not work so well or even fail completely at a given task.</p>
<p>In this blog post, I want to show that if you trained linear regression models, you where already training neural nets (although super simple ones:). I will then go on to derive a slightly more complex neural network from scratch to give an insight into the mathematics behind how training a neural net works.</p>
<div id="linear-regression---the-simplest-neural-network" class="section level2">
<h2>Linear regression - the simplest neural network</h2>
<p>Suppose we have the following simple linear regression model:</p>
<p><span class="math display">\[y_i =  b + \omega_1 x_{i, 1} + \epsilon_i\]</span>
with</p>
<p><span class="math display">\[z = b + \omega_1 x_{i, 1}\]</span></p>
<p>Graphically, our model looks like this:
<div id="htmlwidget-1" style="width:672px;height:480px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"diagram":"\n  digraph rmarkdown { \n  # using different ways to get subscripts to work:)\n  \n  rankdir = LR\n  # nodes\n    1  [shape = square,\n        style = filled,\n        fillcolor = grey]\n    x1 [label = <x<FONT POINT-SIZE=\"8\"><SUB>1<\/SUB><\/FONT>>]\n    z  [label = \"z\"]\n    \n\n  # edges\n    1  -> \"z\" [label = \"b\" ]\n    x1 -> \"z\" [label = <w<FONT POINT-SIZE=\"8\"><SUB>1<\/SUB><\/FONT>>]\n    \"z\" -> \"a\"  [label = \"&sigma;(z)\"]\n  }\n  ","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script></p>
<p>The activation function <span class="math inline">\(\sigma\)</span> decides how a neuron/node ‘fires’ given its activation. In the linear regression case we have <span class="math inline">\(\sigma() = id()\)</span>, i.e. <span class="math inline">\(\sigma()\)</span> equals the identity function.</p>
<p>The constant input <code>1</code> with coefficient <span class="math inline">\(b\)</span> is called the bias in neural network literature and the model and <span class="math inline">\(w\)</span> is called weight.</p>
<p>The standard way to ‘learn’ the coefficients (<span class="math inline">\(w^{(1)}\)</span> and <span class="math inline">\(b\)</span> in this case) for a linear regression model is to use OLS as our training algorithm, assuming that we want to minimize the squared loss <span class="math display">\[(a - y)^2\]</span> between our prediction <span class="math inline">\(a\)</span> and actual results <span class="math inline">\(y\)</span>. However, since linear regression is basically just a very simple neural network, we can also find our coefficients using backpropagation.</p>
</div>
<div id="training-neural-nets-with-backpropagation" class="section level2">
<h2>Training Neural Nets with Backpropagation</h2>
<p>The following exposition is based on the excellent explanation of backpropagation by <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8">3Blue1Brown</a> and on Michael Nielsen’s equally great free <a href="http://neuralnetworksanddeeplearning.com/chap2.html#the_code_for_backpropagation">online book</a>.</p>
<p>Before we start to look at the backpropagation algorithm in detail, we need to introduce two important assumptions for our cost function for backprop to work:</p>
<ol style="list-style-type: decimal">
<li>The cost function can be written as an average over the cost for individual training points <span class="math inline">\(x\)</span>: <span class="math inline">\(C = \frac{1}{n}\sum_x C_x\)</span></li>
<li>The cost function can be written as a function of the neural net outputs.</li>
</ol>
<p>Both assumptions hold, if we use the squared loss, aka a quantratic cost function.</p>
<p>We will now create a slightly more complex example than the linear regression model from above by adding a single hidden layers to our network:
<img src="img/one-hidden-layer-network.PNG" /><!-- --></p>
<p>So, now the question is: How do we find the optimal weights <span class="math inline">\(w^{(1)} \dots w^{(L)}\)</span> and biases <span class="math inline">\(b^{(1)} \dots b^{(L)}\)</span>in our network such that we minimize our cost function <span class="math inline">\(C\)</span>? We need to solve an optimization problem and to do that we need to calculate the gradient of the cost function:
<span class="math display">\[
\nabla C = 
\begin{bmatrix}
  \frac{\partial C}{\partial w^{(1)}} \\
  \frac{\partial C}{\partial b^{(1)}} \\
  \vdots \\
  \frac{\partial C}{\partial w^{(L)}} \\
  \frac{\partial C}{\partial b^{(L)}} \\
\end{bmatrix}
\]</span>
so we can use the Gradient Descent algorithm to find a (local) optimum. Specifically, we will update the weights in each iteration like so:
<span class="math display">\[
\begin{align}
w^{(l)} &amp;\rightarrow w^{(l)} - \eta \frac{\partial C}{\partial w^{(l)}} \\
b^{(l)} &amp;\rightarrow b^{(l)} - \eta \frac{\partial C}{\partial b^{(l)}} 
\end{align}
\]</span>
where <span class="math inline">\(\eta\)</span> is the gradient step-size also called learning rate.</p>
<p>So the question now becomes:</p>
<blockquote>
<p>How do we calculate <span class="math inline">\(\nabla C\)</span>?</p>
</blockquote>
<p>As we can see from our graph, there are 3 ways how we can change the output from our network:</p>
<ol style="list-style-type: decimal">
<li>We can change the weight <span class="math inline">\(w^{(L)}\)</span>.</li>
<li>We can change the bias <span class="math inline">\(b^{(L)}\)</span> or</li>
<li>we change the inputs from previous layers <span class="math inline">\(a^{(L-1)}\)</span>.</li>
</ol>
<p>We have the following relations for layer <span class="math inline">\(L\)</span>:
<span class="math display">\[
\begin{align}
C(a^{(L)}) &amp; = (a^{(L)} - y)^2 \newline
z^{(L)} &amp; = w^{(L)}a^{(L-1)}+b^{(L)} \newline
a^{(L)} &amp; = \sigma(z^{(L)})
\end{align}
\]</span></p>
<p>Using the chain rule we get:
<span class="math display">\[
\frac{\partial C}{\partial w^{(L)}} = 
\underbrace{
  \frac{\partial C}{\partial a^{(L)}}
  \frac{\partial a^{(L)}}{\partial z^{(L)}}
}_{
  =\frac{\partial C^{(L)}}{\partial z^{(L)}} =: \delta^{(L)} 
}
\underbrace{
  \frac{\partial z^{(L)}}{\partial w^{(L)}}
}_{
  =a^{(L-1)}
}
\]</span>
We define the error <span class="math inline">\(\delta^{(L)} := \frac{\partial C^{(L)}}{\partial z^{(L)}}\)</span>, because it tells us how strongly the cost function changes based on changes to <span class="math inline">\(z^{(L)}\)</span>.</p>
<p>We have:</p>
<p><span class="math display">\[
\begin{align}
  \delta^{(L)} &amp;:= \frac{\partial C}{\partial z^{(L)}} 
    = 
    \frac{\partial C}{\partial a^{(L)}}
    \frac{\partial a^{(L)}}{\partial z^{(L)}} \\
    &amp;=2(a^{(L)} - y) \sigma&#39;(z^{(L)}) &amp;\text{... error output layer} \\
  \delta^{(L-1)} &amp;= \frac{\partial C}{\partial z^{(L-1)}} 
    =
    \frac{\partial C}{\partial a^{(L-1)}}  \sigma&#39;(z^{(L)}) \\
    &amp;=
    \underbrace{
      \frac{\partial C}{\partial a^{(L)}}
      \frac{\partial a^{(L)}}{\partial z^{(L)}}
    }_{=\delta^{(L)}}
    \underbrace{
      \frac{\partial z^{(L)}}{\partial a^{(L-1)}}
    }_{w^{(L)}}
    \sigma&#39;(z^{(L)})\\
    &amp;=  \delta^{(L)} w^{(L)}\sigma&#39;(z^{(L)}) 
    &amp;\text{... error hidden layer}
\end{align}
\]</span>
or more generally:
<span class="math display">\[
\delta^{(l)} = \frac{\partial C}{\partial z^{(l)}}=  \delta^{(l+1)} w^{(l+1)}\sigma&#39;(z^{(l)})\text{ ... l-th error hidden layer}
\]</span>
So:
<span class="math display">\[
\frac{\partial C}{\partial w^{(l)}} = \delta^{(l)}a^{(l-1)}
\]</span>
Now we repeat the steps from above to get:
<span class="math display">\[
\frac{\partial C}{\partial b^{(l)}} = \frac{\partial C}{\partial a^{(l)}}
    \frac{\partial a^{(l)}}{\partial z^{(l)}}\frac{\partial z^{(l)}}{\partial b^{(l)}}=\delta^{(l)}1
\]</span></p>
<p>We can now calculate our gradient above if we walk backwards from the output the the input layer, hence the name ‘backpropagation’:)</p>
<p>The backprop equations for a ‘multivariate’ setting are:
<span class="math display">\[
\begin{align}
  \delta^{(L)} &amp;= \nabla_a C \odot \sigma&#39;(z^{(L)})\\
  \delta^{(l)} &amp;=  ((w^{(l+1)})^T\delta^{(l+1)}) \odot \sigma&#39;(z^{(l)}) \\
  \frac{\partial C}{\partial b^{(l)}_j} &amp;= \delta^{(l)}_j \\
  \frac{\partial C}{\partial w^{(l)}_{j,k}} &amp;= \delta^{(l)}_ja^{(l-1)}_k
\end{align}
\]</span>
where <span class="math inline">\(j,k\)</span> refers to the <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span> neuron and <span class="math inline">\(\odot\)</span> is the so called ‘Hadamard product’, i.e. the elementwise matrix product.</p>
<p>I hope you found my post helpful. If you find any errors, just open a Github issue.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li>Neural Networks and Deep Learning: <a href="http://neuralnetworksanddeeplearning.com/chap2.html#the_code_for_backpropagation" class="uri">http://neuralnetworksanddeeplearning.com/chap2.html#the_code_for_backpropagation</a></li>
<li>3Blue1Brown - Backpropagation Calculus: <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8" class="uri">https://www.youtube.com/watch?v=tIeHLnjs5U8</a></li>
</ul>
</div>
